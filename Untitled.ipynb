{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob \n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Baseline system -- IE first-stab \n",
    "Series of experiments that may or may not improve system\n",
    "\n",
    "Here are some questions intended to guide you in this process:\n",
    "\n",
    "1)     In building the baseline system, what shallow text features make sense for the task as a first-stab approach? (e.g., a language modeling approach is a standard way to tackle this problem, i.e., a bag-of-words approach / a unigram model);\n",
    "2)     What machine learning models are suitable for conducting sentiment analysis? (i.e., compare 3-4 learning algorithms). Which performs best given your features?  \n",
    "3)     How would you improve the baseline model? I.e., What text features are most beneficial to the task of sentiment analysis? Experiment with at least 4 different features that go beyond a language modeling representation. \n",
    "4)     How does the size of the feature sets you are experimenting with influence the performance of sentiment analysis? Compare the performance of different feature sets under the same feature selection scenario and machine learning algorithm. For instance, you have several options here: \n",
    "a)     start with the feature set in the baseline model, and then add new features one at at time (i.e., called the incremental approach). For each new such addition, measure the performance on each of the machine learning models you selected at 3). Which of the machine learning models you chose at 2) works best with your features? \n",
    "b)     another way is to add all the new features to the baseline model, then compute their performance with a leave-one-out approach (as you did for Hw#3).\n",
    "For this question you have to compute the performance, then compare and analyze the results. Which is the best combination of features (i.e., best feature set) with which machine learning model and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews=glob.glob('/review_polarity/txt_sentoken/neg/*')\n",
    "print(len(negative_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}